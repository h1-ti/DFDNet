{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/h1-ti/DFDNet/blob/master/DFDNET_FACE_ENHANCER_VIA_COLAB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tJ_vcf2Rcsa"
      },
      "source": [
        "# **実行前の準備**\n",
        "\n",
        "\n",
        "\n",
        "1.   GOOGOLE DRIVE を開き左上の『＋新規』→　フォルダ　→　faceset フォルダを作成\n",
        "2.   ローカル（自分のパソコン）の 1)Faceset/CATEGORYフォルダ を開き、超解像したいSRCをzipで圧縮する。例）1)Faceset/hogezaka/hoge -> 1)Faceset/hogezaka/hoge.zip\n",
        "3.1のfacesetフォルダに2のhoge.zipをアップロード（複数可）\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kT9o8wr-XoPo"
      },
      "source": [
        "# **実行**\n",
        "\n",
        "\n",
        "\n",
        "* このページの上にある　ランタイム（左から５番目）　→　すべてのセルを実行\n",
        "\n",
        "## ※注意  **1.MOUNT GOOGLE DRIVE** のところで入力があります"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tg8amUD0jTUg"
      },
      "source": [
        "### 詳しく"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXLekaNXfH7J"
      },
      "source": [
        "* GOOGLE DRIVEのマウントが完了したら終わるまで待つだけです\n",
        "\n",
        "\n",
        "* 完了すると先ほどのfacesetフォルダにhoge_dfdnet.zipができるのでドライブからダウンロードしてください\n",
        "\n",
        "\n",
        "* ※srcが多すぎると最後まで完了せずに接続が切れるかもしれません。時間をおいてやり直してください。完了したものはスキップされるようになっております\n",
        "\n",
        "* 実行中に新しいsrcのzipをアップすることも可能です\n",
        "\n",
        "\n",
        "* ※また、2.INSTALL and GET MODEL WEIGHTでダウンロードがうまくいかず止まっている場合はやり直してください"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQN1kTWtyNkz"
      },
      "source": [
        "**CHECK VIDEO CARD'S SPEC**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cvm0OvQVk-tS"
      },
      "source": [
        "速さ比較\n",
        "\n",
        " P100(?f/s) > T4(6f/s) > K80(3f/s)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWcpzkH4zygh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a06f279c-6208-4072-85da-be7333000406"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Oct 25 07:26:21 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   52C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7jMlGY-x03o"
      },
      "source": [
        "# **1.MOUNT GOOGLE DRIVE**\n",
        "\n",
        "### ①Go to this URL in a browser:の右のリンクからGOOGLEにログイン\n",
        "### ②Enter your authorization code:の下に①で取得したコードをペーストしてGOOGLE DRIVE をマウント\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgkGoIv80oHK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18512840-8b13-44e1-9914-f5b27b840125"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LWZluDOxg1-"
      },
      "source": [
        "# **2.INSTALL and GET MODEL WEIGHT**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9RvF56eipf-"
      },
      "source": [
        "### install DFDNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w49XiZU8w_K0"
      },
      "source": [
        "%cd /content\n",
        "!git clone --branch master https://github.com/h1-ti/DFDNet.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IwOvQkPizw5"
      },
      "source": [
        "### get weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMi0s85HiYy1"
      },
      "source": [
        "!pip install dominate\n",
        "\n",
        "from IPython.display import clear_output\n",
        "from google.colab import files\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "import os\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "os.chdir('/content/DFDNet/')\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "link_prefix = 'https://github.com/rocketsvm/DFDNet/releases/download/20200827/'\n",
        "wget_options = '-q --show-progress --progress=bar:noscroll --no-check-certificate -r'\n",
        "!wget $wget_options $link_prefix'latest_net_G.pth' -O 'latest_net_G.pth'\n",
        "!wget $wget_options $link_prefix'left_eye_32_center.npy' -O 'left_eye_32_center.npy'\n",
        "!wget $wget_options $link_prefix'left_eye_64_center.npy' -O 'left_eye_64_center.npy'\n",
        "!wget $wget_options $link_prefix'left_eye_128_center.npy' -O 'left_eye_128_center.npy'\n",
        "!wget $wget_options $link_prefix'left_eye_256_center.npy' -O 'left_eye_256_center.npy'\n",
        "!wget $wget_options $link_prefix'right_eye_32_center.npy' -O 'right_eye_32_center.npy'\n",
        "!wget $wget_options $link_prefix'right_eye_64_center.npy' -O 'right_eye_64_center.npy'\n",
        "!wget $wget_options $link_prefix'right_eye_128_center.npy' -O 'right_eye_128_center.npy'\n",
        "!wget $wget_options $link_prefix'right_eye_256_center.npy' -O 'right_eye_256_center.npy'\n",
        "!wget $wget_options $link_prefix'mouth_32_center.npy' -O 'mouth_32_center.npy'\n",
        "!wget $wget_options $link_prefix'mouth_64_center.npy' -O 'mouth_64_center.npy'\n",
        "!wget $wget_options $link_prefix'mouth_128_center.npy' -O 'mouth_128_center.npy'\n",
        "!wget $wget_options $link_prefix'mouth_256_center.npy' -O 'mouth_256_center.npy'\n",
        "!wget $wget_options $link_prefix'nose_32_center.npy' -O 'nose_32_center.npy'\n",
        "!wget $wget_options $link_prefix'nose_64_center.npy' -O 'nose_64_center.npy'\n",
        "!wget $wget_options $link_prefix'nose_128_center.npy' -O 'nose_128_center.npy'\n",
        "!wget $wget_options $link_prefix'nose_256_center.npy' -O 'nose_256_center.npy'\n",
        "!wget $wget_options $link_prefix'vgg19.pth' -O 'vgg19.pth'\n",
        "!mkdir -p /content/DFDNet/checkpoints/facefh_dictionary\n",
        "!mv latest_net_G.pth /content/DFDNet/checkpoints/facefh_dictionary\n",
        "!mkdir -p /content/DFDNet/DictionaryCenter512\n",
        "!mv *_center.npy /content/DFDNet/DictionaryCenter512\n",
        "!mkdir -p /content/DFDNet/weights\n",
        "!mv vgg19.pth /content/DFDNet/weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aH9EtRb73CVY"
      },
      "source": [
        "# **3.FACE ENHANCE PROCESS**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBTNvtBH09Y8",
        "outputId": "ffb8858d-3cbf-4017-dc6d-45b0e52f20ec"
      },
      "source": [
        "%cd /content/DFDNet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfJEX7oo28ne",
        "cellView": "form"
      },
      "source": [
        "#@title FACE ENHANCE PROCESS\n",
        "\n",
        "import sys\n",
        "import os, os.path as osp\n",
        "import argparse\n",
        "import zipfile\n",
        "import glob\n",
        "import cv2\n",
        "import shutil\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "from util import util\n",
        "import models\n",
        "from models import create_model\n",
        "import data\n",
        "from data.image_folder import make_dataset\n",
        "from options.test_options import TestOptions\n",
        "from DFLIMG.DFLPNG import DFLPNG\n",
        "from DFLIMG.DFLJPG import DFLJPG\n",
        "\n",
        "root = \"/content/DFDNET\"\n",
        "\n",
        "OUT_RES = 512\n",
        "    \n",
        "faceset_dir = \"/content/drive/MyDrive/faceset\"\n",
        "indir = osp.join(root, \"temp_input\")\n",
        "os.makedirs(indir, exist_ok=True)\n",
        "\n",
        "class TestOptions2(TestOptions):\n",
        "    def __init__(self) -> None:\n",
        "        super().__init__()\n",
        "    \n",
        "    # override\n",
        "    def gather_options(self):\n",
        "        # initialize parser with basic options\n",
        "        if not self.initialized:\n",
        "            parser = argparse.ArgumentParser(\n",
        "                formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
        "            parser = self.initialize(parser)\n",
        "        \n",
        "        opt, _ = parser.parse_known_args()\n",
        "        # modify model-related parser options\n",
        "        model_name = opt.model\n",
        "        model_option_setter = models.get_option_setter(model_name)\n",
        "        parser = model_option_setter(parser, self.isTrain)\n",
        "\n",
        "        opt, _ = parser.parse_known_args()  # parse again with the new defaults\n",
        "\n",
        "        # modify dataset-related parser options\n",
        "        dataset_name = opt.dataset_mode\n",
        "\n",
        "        dataset_option_setter = data.get_option_setter(dataset_name)\n",
        "        parser = dataset_option_setter(parser, self.isTrain)\n",
        "\n",
        "        self.parser = parser\n",
        "        opt, _ = parser.parse_known_args()\n",
        "        return opt\n",
        "\n",
        "def get_part_location(lmrks):\n",
        "    Landmarks = []\n",
        "    \n",
        "    Landmarks = np.array(lmrks)\n",
        "    \n",
        "    Map_LE = list(np.hstack((range(17,22), range(36,42))))\n",
        "    Map_RE = list(np.hstack((range(22,27), range(42,48))))\n",
        "    Map_NO = list(range(29,36))\n",
        "    Map_MO = list(range(48,68))\n",
        "    try:\n",
        "        #left eye\n",
        "        Mean_LE = np.mean(Landmarks[Map_LE],0)\n",
        "        L_LE = np.max((np.max(np.max(Landmarks[Map_LE],0) - np.min(Landmarks[Map_LE],0))/2,16))\n",
        "        Location_LE = np.hstack((Mean_LE - L_LE + 1, Mean_LE + L_LE)).astype(int)\n",
        "        #right eye\n",
        "        Mean_RE = np.mean(Landmarks[Map_RE],0)\n",
        "        L_RE = np.max((np.max(np.max(Landmarks[Map_RE],0) - np.min(Landmarks[Map_RE],0))/2,16))\n",
        "        Location_RE = np.hstack((Mean_RE - L_RE + 1, Mean_RE + L_RE)).astype(int)\n",
        "        #nose\n",
        "        Mean_NO = np.mean(Landmarks[Map_NO],0)\n",
        "        L_NO = np.max((np.max(np.max(Landmarks[Map_NO],0) - np.min(Landmarks[Map_NO],0))/2,16))\n",
        "        Location_NO = np.hstack((Mean_NO - L_NO + 1, Mean_NO + L_NO)).astype(int)\n",
        "        #mouth\n",
        "        Mean_MO = np.mean(Landmarks[Map_MO],0)\n",
        "        L_MO = np.max((np.max(np.max(Landmarks[Map_MO],0) - np.min(Landmarks[Map_MO],0))/2,16))\n",
        "        Location_MO = np.hstack((Mean_MO - L_MO + 1, Mean_MO + L_MO)).astype(int)\n",
        "    except:\n",
        "        return 0\n",
        "    return torch.from_numpy(Location_LE).unsqueeze(0), torch.from_numpy(Location_RE).unsqueeze(0), torch.from_numpy(Location_NO).unsqueeze(0), torch.from_numpy(Location_MO).unsqueeze(0)\n",
        "\n",
        "opt = TestOptions2().parse()\n",
        "\n",
        "opt.gpu_ids = [0] # gpu id. if use cpu, set opt.gpu_ids = []\n",
        "jpeg_quality = opt.jpeg_quality\n",
        "model = create_model(opt)\n",
        "model.setup(opt)\n",
        "\n",
        "done = []\n",
        "\n",
        "while True:\n",
        "    src_names = [osp.splitext(d)[0] for d in os.listdir(faceset_dir)\n",
        "             if osp.splitext(d)[1] == \".zip\" and \"_dfdnet\" not in d and \"_superres\" not in d\n",
        "             and not osp.exists(osp.join(faceset_dir, osp.splitext(d)[0]+\"_dfdnet.zip\"))\n",
        "             and osp.splitext(d)[0] not in done]\n",
        "    if len(src_names) == 0:\n",
        "        break\n",
        "    print(src_names)\n",
        "    \n",
        "    for id, src in enumerate(src_names):\n",
        "        print(\"{} / {} [{}]\".format(id+1, len(src_names), src))\n",
        "        zip_path = osp.join(faceset_dir, src+\".zip\")\n",
        "        print(\"Extracting [{}] ...\".format(zip_path))\n",
        "        with zipfile.ZipFile(zip_path) as z:\n",
        "            z.extractall(indir)\n",
        "\n",
        "        files = sorted(glob.glob(osp.join(indir, src, '*.*g')))\n",
        "\n",
        "        outdir = osp.join(root, src+\"_dfdnet\", src+\"_dfdnet\")\n",
        "        os.makedirs(outdir, exist_ok=True)\n",
        "\n",
        "        for n, file in enumerate(tqdm(files[:], total=len(files), desc=\"Enhancing faces ...\")):\n",
        "            filename = osp.basename(file)\n",
        "            ext = osp.splitext(file)[1]\n",
        "            if ext == \".jpg\":\n",
        "                dflimg = DFLJPG.load(file)\n",
        "            elif ext == \".png\":\n",
        "                dflimg = DFLPNG.load(file)\n",
        "            else:\n",
        "                continue\n",
        "\n",
        "            if not dflimg:\n",
        "                continue\n",
        "\n",
        "            Landmarks = dflimg.get_landmarks()\n",
        "            # InputData = dflimg.dfl_dict\n",
        "        \n",
        "            # scale landmarks and xseg polys to output image size\n",
        "            scale_factor = OUT_RES / dflimg.get_shape()[0]\n",
        "            # print('Scale factor: {}'.format(scale_factor))\n",
        "            Landmarks = Landmarks * scale_factor\n",
        "            \n",
        "            Part_locations = get_part_location(Landmarks)\n",
        "            A = Image.open(file).convert('RGB')\n",
        "            \n",
        "            if Part_locations == 0:\n",
        "                print('\\t################ Error in landmarks, continue...')\n",
        "                continue\n",
        "            C = A\n",
        "            A = A.resize((OUT_RES, OUT_RES), Image.BICUBIC)\n",
        "            A = transforms.ToTensor()(A) \n",
        "            C = transforms.ToTensor()(C)\n",
        "            A = transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))(A)\n",
        "            C = transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))(C)\n",
        "            \n",
        "            data = {'A':A.unsqueeze(0), 'C':C.unsqueeze(0), 'A_paths': file,'Part_locations': Part_locations}\n",
        "\n",
        "            model.set_input(data)\n",
        "            try:\n",
        "                model.test()\n",
        "                visuals = model.get_current_visuals()\n",
        "                \n",
        "                im_data = visuals['fake_A']\n",
        "                im = util.tensor2im(im_data)\n",
        "                image_pil = Image.fromarray(im)\n",
        "                if ext == \".jpg\":\n",
        "                    image_pil.save(osp.join(outdir, filename), quality=jpeg_quality)\n",
        "                else:\n",
        "                    image_pil.save(osp.join(outdir, filename))\n",
        "            \n",
        "            except Exception as e:\n",
        "                print('\\t################ Error enhancing {}'.format(str(e)))\n",
        "                continue\n",
        "\n",
        "            if ext == \".jpg\":\n",
        "                _fanseg_mask = dflimg.dfl_dict.get('fanseg_mask', None)\n",
        "                if _fanseg_mask is not None:\n",
        "                    ret, buf = cv2.imencode( '.jpg', _fanseg_mask, [int(cv2.IMWRITE_JPEG_QUALITY), 85] )\n",
        "\n",
        "                    if ret and len(buf) < 64000:\n",
        "                        _fanseg_mask = buf\n",
        "                    else:\n",
        "                        io.log_err(\"Unable to encode fanseg_mask for %s\" % (filename) )\n",
        "                        _fanseg_mask = None\n",
        "\n",
        "                _xseg_mask = dflimg.dfl_dict.get('xseg_mask', None)\n",
        "                if _xseg_mask is not None:\n",
        "                    ret, buf = cv2.imencode( '.jpg', _xseg_mask, [int(cv2.IMWRITE_JPEG_QUALITY), 85] )\n",
        "\n",
        "                    if ret and len(buf) < 64000:\n",
        "                        _xseg_mask = buf\n",
        "                    else:\n",
        "                        io.log_err(\"Unable to encode xseg_mask for %s\" % (filename) )\n",
        "                        _xseg_mask = None\n",
        "\n",
        "                DFLJPG.embed_dfldict (osp.join(outdir, filename), \n",
        "                                        {'face_type': dflimg.get_face_type(),\n",
        "                                            'landmarks': dflimg.get_landmarks(),\n",
        "                                            'ie_polys' : dflimg.get_ie_polys(),\n",
        "                                            'source_filename': dflimg.get_source_filename(),\n",
        "                                            'source_rect': dflimg.get_source_rect(),\n",
        "                                            'source_landmarks': dflimg.get_source_landmarks(),\n",
        "                                            'image_to_face_mat': dflimg.get_image_to_face_mat(),\n",
        "                                            'fanseg_mask' : _fanseg_mask,\n",
        "                                            'xseg_mask' : _xseg_mask,\n",
        "                                            'eyebrows_expand_mod' : None,\n",
        "                                            'relighted' : None,\n",
        "                                            \"histgram\" : None,\n",
        "                                            \"recognition\" : dflimg.get_recognition(),\n",
        "                                        })\n",
        "            elif ext == \".png\":\n",
        "                dflimg = DFLPNG.embed_dfldict (osp.join(outdir, filename), \n",
        "                                        {'face_type': dflimg.get_face_type(),\n",
        "                                            'landmarks': Landmarks,\n",
        "                                            'ie_polys' : dflimg.get_ie_polys(),\n",
        "                                            'source_filename': dflimg.get_source_filename(),\n",
        "                                            'source_rect': dflimg.get_source_rect(),\n",
        "                                            'source_landmarks': dflimg.get_source_landmarks(),\n",
        "                                            'image_to_face_mat': dflimg.get_image_to_face_mat(),\n",
        "                                            'fanseg_mask' : dflimg.dfl_dict.get ('fanseg_mask', None),\n",
        "                                            'xseg_mask' : dflimg.dfl_dict.get('xseg_mask', None),\n",
        "                                            'eyebrows_expand_mod' : None,\n",
        "                                            'relighted' : None,\n",
        "                                            \"histgram\" : None,\n",
        "                                            \"recognition\" : dflimg.get_recognition(),\n",
        "                                        })\n",
        "\n",
        "\n",
        "        \n",
        "        shutil.make_archive(src+\"_dfdnet\", 'zip', src+\"_dfdnet\")\n",
        "        if osp.exists(osp.join(faceset_dir, src+\"_dfdnet.zip\")):\n",
        "            os.remove(osp.join(faceset_dir, src+\"_dfdnet.zip\"))\n",
        "        shutil.move(src+\"_dfdnet.zip\", faceset_dir)\n",
        "        shutil.rmtree(src+\"_dfdnet\")\n",
        "        print(\"Successfully completed {}\".format(src+\"_dfdnet\"))\n",
        "        done.append(src)\n",
        "\n",
        "print(done)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}